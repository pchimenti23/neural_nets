{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_iRmBWK1Zrt"
      },
      "source": [
        "**This notebook walks through the steps of applying transfer learning for image recognition.  Pytorch has many pretrained models that can be adapted to a given application.  The pretrained models simply need to be loaded and adapated for the given application.**\n",
        "\n",
        "**For this case, ten objects will be classified from the CIFAR-10 (https://www.cs.toronto.edu/~kriz/cifar.html) data set.  The pretrained Inception-v3 (https://arxiv.org/abs/1512.00567) model will be adapted to classify these images.**\n",
        "\n",
        "**The ten objects to be classified are:**\n",
        "\n",
        "*   airplane\n",
        "*   automobile\n",
        "*   bird\n",
        "*   cat\n",
        "*   deer\n",
        "*   dog\n",
        "*   frog\n",
        "*   horse\n",
        "*   ship\n",
        "*   truck\n",
        "\n",
        "**Note that truck here refers to large semi type trucks.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UhAEpQt_u0Z"
      },
      "source": [
        "**First load the necessary packages.  Note that 'models' is being imported from 'torchvision'.  This gives access to many pretrained models.  Pretrained models can be obtained elsewhere as well but this package gives plenty of options for our purposes.**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "8rKyNz1U__mc"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms, models\n",
        "\n",
        "#from collections import OrderedDict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2jJRRDVSQO9"
      },
      "source": [
        "**The CIFAR-10 data set is included in the `torchvision.datasets` module.  It is loaded below.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-9Ihm4IXTpF"
      },
      "source": [
        "**Images need to undergo transformations before being loaded.  First the transforms for the training set are defined.**\n",
        "\n",
        "**The random rotation aids in training.  It will allow the network to see the image from different angles during each training pass.  This will help the network to generalize.  Randomness is also added to the cropping step.  The inception v3 net is unique in that it expects size 299 (299x299 pixels).  Most models take size 224 but sometimes it is fun to be different.  A random horizontal flip is added to further aid in generalization and the normalization is defined to fit what the pretrained network expects.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "jB_ByaEfXbdG"
      },
      "outputs": [],
      "source": [
        "train_transforms = transforms.Compose([transforms.RandomRotation(30),\n",
        "                                       transforms.RandomResizedCrop(299),\n",
        "                                       transforms.RandomHorizontalFlip(),\n",
        "                                       transforms.ToTensor(),\n",
        "                                       transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                                                            [0.229, 0.224, 0.225])])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E19SwHjhZMp3"
      },
      "source": [
        "**No randomness is added to the test set as accuracy should be graded on the true images.  However, they are resized and then cropped to fit what the net expects.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "7ASpCPEuXcD0"
      },
      "outputs": [],
      "source": [
        "test_transforms = transforms.Compose([transforms.Resize(320),\n",
        "                                      transforms.CenterCrop(299),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                                                           [0.229, 0.224, 0.225])])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lIN0ACfgafqW"
      },
      "source": [
        "**The train and test set are loaded below using the data loader utility.  Batches of 64 images at a time will be passed through the model.  The training set will be randomly shuffled to prevent the net from picking up patterns based on the order images are seen.  This is not necessary for the test set.  Notice that the train and test transforms are applied at this step.**  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GTgT2EI4SQbM",
        "outputId": "096e913e-0f7e-42d9-a5bf-c08d84f7682a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=train_transforms)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=test_transforms)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=64, drop_last = True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SK7QwfGEapMz"
      },
      "source": [
        "**The classes are defined listed below in the order they are indexed (alphabetically).**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "xJDbwoc4apgV"
      },
      "outputs": [],
      "source": [
        "classes = ('airplane', 'automobile', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JmkT3JB3rv4m"
      },
      "source": [
        "**The inception v3 model is loaded and described below.  It is pretrained but the output configuration needs to be determined in order to properly attach new layers.  Only 10 output layers are needed for this classification problem whereas the pretrained model outputs 1,000.  The key here is to recognize that the last layer takes 2,048 features and is named as (fc).  A small neural net will basically be attached to this layer and a new output layer will be constructed.  Syntactically this new small net will be named as (fc) and will replace the old output layer.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJQvHo6Okj9x",
        "outputId": "0fc275a2-d92c-49f7-e00b-0e14380fdc2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
            "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=Inception_V3_Weights.IMAGENET1K_V1`. You can also use `weights=Inception_V3_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Inception3(\n",
              "  (Conv2d_1a_3x3): BasicConv2d(\n",
              "    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (Conv2d_2a_3x3): BasicConv2d(\n",
              "    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
              "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (Conv2d_2b_3x3): BasicConv2d(\n",
              "    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (Conv2d_3b_1x1): BasicConv2d(\n",
              "    (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "    (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (Conv2d_4a_3x3): BasicConv2d(\n",
              "    (conv): Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
              "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (maxpool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (Mixed_5b): InceptionA(\n",
              "    (branch1x1): BasicConv2d(\n",
              "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch5x5_1): BasicConv2d(\n",
              "      (conv): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch5x5_2): BasicConv2d(\n",
              "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_1): BasicConv2d(\n",
              "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_2): BasicConv2d(\n",
              "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_3): BasicConv2d(\n",
              "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch_pool): BasicConv2d(\n",
              "      (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (Mixed_5c): InceptionA(\n",
              "    (branch1x1): BasicConv2d(\n",
              "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch5x5_1): BasicConv2d(\n",
              "      (conv): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch5x5_2): BasicConv2d(\n",
              "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_1): BasicConv2d(\n",
              "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_2): BasicConv2d(\n",
              "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_3): BasicConv2d(\n",
              "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch_pool): BasicConv2d(\n",
              "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (Mixed_5d): InceptionA(\n",
              "    (branch1x1): BasicConv2d(\n",
              "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch5x5_1): BasicConv2d(\n",
              "      (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch5x5_2): BasicConv2d(\n",
              "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_1): BasicConv2d(\n",
              "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_2): BasicConv2d(\n",
              "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_3): BasicConv2d(\n",
              "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch_pool): BasicConv2d(\n",
              "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (Mixed_6a): InceptionB(\n",
              "    (branch3x3): BasicConv2d(\n",
              "      (conv): Conv2d(288, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_1): BasicConv2d(\n",
              "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_2): BasicConv2d(\n",
              "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_3): BasicConv2d(\n",
              "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (Mixed_6b): InceptionC(\n",
              "    (branch1x1): BasicConv2d(\n",
              "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7_1): BasicConv2d(\n",
              "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7_2): BasicConv2d(\n",
              "      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7_3): BasicConv2d(\n",
              "      (conv): Conv2d(128, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_1): BasicConv2d(\n",
              "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_2): BasicConv2d(\n",
              "      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_3): BasicConv2d(\n",
              "      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_4): BasicConv2d(\n",
              "      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_5): BasicConv2d(\n",
              "      (conv): Conv2d(128, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch_pool): BasicConv2d(\n",
              "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (Mixed_6c): InceptionC(\n",
              "    (branch1x1): BasicConv2d(\n",
              "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7_1): BasicConv2d(\n",
              "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7_2): BasicConv2d(\n",
              "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7_3): BasicConv2d(\n",
              "      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_1): BasicConv2d(\n",
              "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_2): BasicConv2d(\n",
              "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_3): BasicConv2d(\n",
              "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_4): BasicConv2d(\n",
              "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_5): BasicConv2d(\n",
              "      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch_pool): BasicConv2d(\n",
              "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (Mixed_6d): InceptionC(\n",
              "    (branch1x1): BasicConv2d(\n",
              "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7_1): BasicConv2d(\n",
              "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7_2): BasicConv2d(\n",
              "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7_3): BasicConv2d(\n",
              "      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_1): BasicConv2d(\n",
              "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_2): BasicConv2d(\n",
              "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_3): BasicConv2d(\n",
              "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_4): BasicConv2d(\n",
              "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_5): BasicConv2d(\n",
              "      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch_pool): BasicConv2d(\n",
              "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (Mixed_6e): InceptionC(\n",
              "    (branch1x1): BasicConv2d(\n",
              "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7_1): BasicConv2d(\n",
              "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7_2): BasicConv2d(\n",
              "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7_3): BasicConv2d(\n",
              "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_1): BasicConv2d(\n",
              "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_2): BasicConv2d(\n",
              "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_3): BasicConv2d(\n",
              "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_4): BasicConv2d(\n",
              "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7dbl_5): BasicConv2d(\n",
              "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch_pool): BasicConv2d(\n",
              "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (AuxLogits): InceptionAux(\n",
              "    (conv0): BasicConv2d(\n",
              "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (conv1): BasicConv2d(\n",
              "      (conv): Conv2d(128, 768, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (fc): Linear(in_features=768, out_features=1000, bias=True)\n",
              "  )\n",
              "  (Mixed_7a): InceptionD(\n",
              "    (branch3x3_1): BasicConv2d(\n",
              "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3_2): BasicConv2d(\n",
              "      (conv): Conv2d(192, 320, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7x3_1): BasicConv2d(\n",
              "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7x3_2): BasicConv2d(\n",
              "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7x3_3): BasicConv2d(\n",
              "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch7x7x3_4): BasicConv2d(\n",
              "      (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (Mixed_7b): InceptionE(\n",
              "    (branch1x1): BasicConv2d(\n",
              "      (conv): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3_1): BasicConv2d(\n",
              "      (conv): Conv2d(1280, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3_2a): BasicConv2d(\n",
              "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
              "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3_2b): BasicConv2d(\n",
              "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
              "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_1): BasicConv2d(\n",
              "      (conv): Conv2d(1280, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_2): BasicConv2d(\n",
              "      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_3a): BasicConv2d(\n",
              "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
              "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_3b): BasicConv2d(\n",
              "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
              "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch_pool): BasicConv2d(\n",
              "      (conv): Conv2d(1280, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (Mixed_7c): InceptionE(\n",
              "    (branch1x1): BasicConv2d(\n",
              "      (conv): Conv2d(2048, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3_1): BasicConv2d(\n",
              "      (conv): Conv2d(2048, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3_2a): BasicConv2d(\n",
              "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
              "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3_2b): BasicConv2d(\n",
              "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
              "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_1): BasicConv2d(\n",
              "      (conv): Conv2d(2048, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_2): BasicConv2d(\n",
              "      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_3a): BasicConv2d(\n",
              "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
              "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch3x3dbl_3b): BasicConv2d(\n",
              "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
              "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (branch_pool): BasicConv2d(\n",
              "      (conv): Conv2d(2048, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ],
      "source": [
        "model = models.inception_v3(pretrained = True)\n",
        "model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jpHOcv8o-AuD"
      },
      "source": [
        "**The first step in constructing a custom net from a pretrained net is to freeze the pretrained model.  New layers will be trained but the everything about the pretrained model being leveraged should remain the same.  Therefore the gradients are turned off.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "_nTy9zEJnSVc"
      },
      "outputs": [],
      "source": [
        "for param in model.parameters():\n",
        "    param.requires_grad = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gg1FQgPY-ok1"
      },
      "source": [
        "**Now the old output layer will be replaced with the small net defined below.  It will start with a layer that takes 2,048 features as its input and it will output a log probability for each class.**\n",
        "\n",
        "**Two fully connected rectified linear (ReLU) layers are built.  The first takes in the 2,048 features the model currently inputs to its output layer and instead outputs 500 features.  The next layer inputs those 500 and outputs 250 features.  Finally, those 250 features are converted into 10 outputs with a log softmax layer.  Note that dropout of .2 is used for both ReLU layers to combat overfitting.  This image classifier is trained to recognize 1,000 different image classes and this application only needs to classify 10**\n",
        "\n",
        "**A good exercise would be to play with this architecture and see how it affects final accuracy.  Only a few tests were done on different configurations due to a limited gpu budget and time constraints.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "PH6TCvNLnsCa"
      },
      "outputs": [],
      "source": [
        "model.fc = nn.Sequential(nn.Linear(2048, 500),\n",
        "                                 nn.ReLU(),\n",
        "                                 nn.Dropout(.2), \n",
        "                                 nn.Linear(500, 250),\n",
        "                                 nn.ReLU(),\n",
        "                                 nn.Dropout(.2), \n",
        "                                 nn.Linear(250, 10),\n",
        "                                 nn.LogSoftmax(dim=1))          "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0VPLFd2hAxXA"
      },
      "source": [
        "**Negative log likelihood loss is chosen as the cost function.  Adam is chosen as the optimizer.  Documentation on the Adam optimizer is easy to find but outside the scope of this tutorial.  At this point, it is sufficient to know that it is basically a \"souped up\" version of gradient descent.**\n",
        "\n",
        "**Note the `to(\"cuda\")` command when defining the loss function.  This is the first of a few objects that needs to be moved to the gpu to drastically speed up training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "iLCJyl-yAUMj"
      },
      "outputs": [],
      "source": [
        "criterion = nn.NLLLoss().to(\"cuda\")\n",
        "optimizer = optim.Adam(model.fc.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BVTHqe4QBjy9"
      },
      "source": [
        "**Now the model is ready to be trained.  Loss is being tracked after every batch just for fun.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u1DPsRdjxdiO"
      },
      "source": [
        "**Much of the code below is explained in the 'income_model_binary_nn.ipynb' notebook in the same repo as this notebook.  This code is tracked differently simply for demonstration purposes and because it is fun to watch the model work (at least for me).**\n",
        "\n",
        "**A big difference worth addressing is following two lines:**\n",
        "\n",
        "                  `logps_t = model.forward(images)\n",
        "                   logps = logps_t[0] #inception v3 outputs a tuple in train mode`\n",
        "                    \n",
        "**The code above is necessary because the inception v3 model outputs a tuple containing two tensors.  Position `[0]` in the tensor is the log proabilities that are needed to make predictions.  Position `[1]` contains the auxiliary logits with dimesionality equal to the original model's output (1,000).  That output is not needed so the log probabilities are stored and the auxiliary logits are ignored.**\n",
        "\n",
        "**A fun exercise would be to store the batch and loss and make some plots that (hopefully) show the loss decreasing.  This is usually tracked across epochs but that takes a lot longer to run and gpu time can be limited for most people.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "Br-ET5x0k3Uw"
      },
      "outputs": [],
      "source": [
        "model = model.to(\"cuda\") #model is also moved to the gpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XbEVdBhfCTx7",
        "outputId": "e592d186-450f-44c8-99a1-4015ce454574"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1.. Train loss: 1.821.. \n"
          ]
        }
      ],
      "source": [
        "epochs = 1\n",
        "batch = 0\n",
        "\n",
        "for epoch in range(epochs):\n",
        "     \n",
        "    running_loss = 0\n",
        "    \n",
        "    for images, labels in trainloader:\n",
        "      \n",
        "        #images and labels are moved to gpu as well\n",
        "        images = images.to(\"cuda\")\n",
        "        labels = labels.to(\"cuda\")\n",
        "        \n",
        "        batch += 1\n",
        "        \n",
        "        model.train()\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        logps_t = model.forward(images)\n",
        "        logps = logps_t[0] #inception v3 outputs a tuple in train mode\n",
        "        loss = criterion(logps, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        running_loss += loss.item()\n",
        "        \n",
        "#         print(f\"Epoch {epoch+1} Batch {batch}.. \"\n",
        "#               f\"Train loss: {train_loss:.3f}.. \")\n",
        "\n",
        "    train_loss = running_loss/batch\n",
        "\n",
        "    print(f\"Epoch {epoch+1}.. \"\n",
        "          f\"Train loss: {train_loss:.3f}.. \")\n",
        "            "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8MLpXygs0wsu"
      },
      "source": [
        "**Since this model has only been run for one epoch, the full model can be saved and training resumed at a later time.  Code to load the model is provided below as well.**\n",
        "\n",
        "**First the google drive will be mounted and then the model will be saved in a folder called 'models' in the google drive.  The mounting code only needs to be run once per session so comment it out after running if models will be saved/loaded multiple times.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "_sEA6oOA0pM8"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FN6Mjc812guZ"
      },
      "source": [
        "**The model has been named 'inception_v3_transfer' and stored on the drive.  It can be loaded with the code that is currently commented out.**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "x0cAIiyX2jYJ"
      },
      "outputs": [],
      "source": [
        "# model_name = 'inception_v3_transfer.pt'\n",
        "# path = F'/content/gdrive/My Drive/models/{model_name}'\n",
        "# torch.save(model, path)\n",
        "\n",
        "# model = torch.load('/content/gdrive/My Drive/models/inception_v3_transfer.pt')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CUEvT0p8wsrp"
      },
      "source": [
        "**Predictions are made below.  Loss and accuracy are both tracked but should not change by batch outside of some random variation.  The model has been switched to evaluation mode so that it will remain static.  In regular practice, accuracy for each batch would be stored and aggregated to get an overall accuracy metric.**\n",
        "\n",
        "**Note that in evaluation mode, this model now only outputs the tensor of log probabilities.  This is because the auxiliary logits are only needed for training.  And since log probabilities are less useful, the `torch.exp()` function is used to convert the output to probabilities.**\n",
        "\n",
        "**The predictions and labels are also being stored to do some fun analysis.  `preds` and `true` will store the predictions and true labels, respectively, as a list of tensors.  Data manipulations will be performed to make it possible to get some specific information about model performance.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UOiW15fUP5J4",
        "outputId": "8a3251e6-62af-4ec3-da13-bb259789ff02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 1.. Test loss: 1.256.. Accuracy: 0.59375.. \n",
            "Batch 2.. Test loss: 1.352.. Accuracy: 0.53125.. \n",
            "Batch 3.. Test loss: 1.344.. Accuracy: 0.515625.. \n",
            "Batch 4.. Test loss: 1.253.. Accuracy: 0.53125.. \n",
            "Batch 5.. Test loss: 1.189.. Accuracy: 0.53125.. \n",
            "Batch 6.. Test loss: 1.202.. Accuracy: 0.59375.. \n",
            "Batch 7.. Test loss: 1.351.. Accuracy: 0.546875.. \n",
            "Batch 8.. Test loss: 1.191.. Accuracy: 0.5625.. \n",
            "Batch 9.. Test loss: 1.129.. Accuracy: 0.609375.. \n",
            "Batch 10.. Test loss: 1.151.. Accuracy: 0.59375.. \n",
            "Batch 11.. Test loss: 1.155.. Accuracy: 0.546875.. \n",
            "Batch 12.. Test loss: 1.185.. Accuracy: 0.65625.. \n",
            "Batch 13.. Test loss: 1.281.. Accuracy: 0.578125.. \n",
            "Batch 14.. Test loss: 1.290.. Accuracy: 0.484375.. \n",
            "Batch 15.. Test loss: 1.160.. Accuracy: 0.578125.. \n",
            "Batch 16.. Test loss: 0.983.. Accuracy: 0.71875.. \n",
            "Batch 17.. Test loss: 1.181.. Accuracy: 0.65625.. \n",
            "Batch 18.. Test loss: 1.328.. Accuracy: 0.546875.. \n",
            "Batch 19.. Test loss: 1.036.. Accuracy: 0.6875.. \n",
            "Batch 20.. Test loss: 1.221.. Accuracy: 0.625.. \n",
            "Batch 21.. Test loss: 1.109.. Accuracy: 0.59375.. \n",
            "Batch 22.. Test loss: 1.284.. Accuracy: 0.5.. \n",
            "Batch 23.. Test loss: 1.097.. Accuracy: 0.671875.. \n",
            "Batch 24.. Test loss: 1.315.. Accuracy: 0.5625.. \n",
            "Batch 25.. Test loss: 1.316.. Accuracy: 0.5625.. \n",
            "Batch 26.. Test loss: 1.333.. Accuracy: 0.5.. \n",
            "Batch 27.. Test loss: 1.178.. Accuracy: 0.640625.. \n",
            "Batch 28.. Test loss: 1.190.. Accuracy: 0.640625.. \n",
            "Batch 29.. Test loss: 1.259.. Accuracy: 0.640625.. \n",
            "Batch 30.. Test loss: 1.164.. Accuracy: 0.65625.. \n",
            "Batch 31.. Test loss: 1.293.. Accuracy: 0.546875.. \n",
            "Batch 32.. Test loss: 1.287.. Accuracy: 0.5625.. \n",
            "Batch 33.. Test loss: 1.178.. Accuracy: 0.609375.. \n",
            "Batch 34.. Test loss: 1.338.. Accuracy: 0.53125.. \n",
            "Batch 35.. Test loss: 1.281.. Accuracy: 0.640625.. \n",
            "Batch 36.. Test loss: 1.294.. Accuracy: 0.5625.. \n",
            "Batch 37.. Test loss: 1.293.. Accuracy: 0.5625.. \n",
            "Batch 38.. Test loss: 1.227.. Accuracy: 0.640625.. \n",
            "Batch 39.. Test loss: 1.090.. Accuracy: 0.65625.. \n",
            "Batch 40.. Test loss: 1.604.. Accuracy: 0.359375.. \n",
            "Batch 41.. Test loss: 1.137.. Accuracy: 0.5625.. \n",
            "Batch 42.. Test loss: 1.128.. Accuracy: 0.65625.. \n",
            "Batch 43.. Test loss: 1.013.. Accuracy: 0.75.. \n",
            "Batch 44.. Test loss: 1.285.. Accuracy: 0.578125.. \n",
            "Batch 45.. Test loss: 1.129.. Accuracy: 0.625.. \n",
            "Batch 46.. Test loss: 1.146.. Accuracy: 0.6875.. \n",
            "Batch 47.. Test loss: 1.272.. Accuracy: 0.484375.. \n",
            "Batch 48.. Test loss: 1.156.. Accuracy: 0.625.. \n",
            "Batch 49.. Test loss: 1.239.. Accuracy: 0.59375.. \n",
            "Batch 50.. Test loss: 1.237.. Accuracy: 0.625.. \n",
            "Batch 51.. Test loss: 1.367.. Accuracy: 0.5625.. \n",
            "Batch 52.. Test loss: 1.095.. Accuracy: 0.671875.. \n",
            "Batch 53.. Test loss: 1.399.. Accuracy: 0.546875.. \n",
            "Batch 54.. Test loss: 1.211.. Accuracy: 0.625.. \n",
            "Batch 55.. Test loss: 1.253.. Accuracy: 0.578125.. \n",
            "Batch 56.. Test loss: 1.061.. Accuracy: 0.703125.. \n",
            "Batch 57.. Test loss: 1.240.. Accuracy: 0.515625.. \n",
            "Batch 58.. Test loss: 1.177.. Accuracy: 0.515625.. \n",
            "Batch 59.. Test loss: 1.256.. Accuracy: 0.515625.. \n",
            "Batch 60.. Test loss: 1.121.. Accuracy: 0.625.. \n",
            "Batch 61.. Test loss: 1.145.. Accuracy: 0.640625.. \n",
            "Batch 62.. Test loss: 1.166.. Accuracy: 0.625.. \n",
            "Batch 63.. Test loss: 1.305.. Accuracy: 0.546875.. \n",
            "Batch 64.. Test loss: 1.268.. Accuracy: 0.640625.. \n",
            "Batch 65.. Test loss: 1.265.. Accuracy: 0.578125.. \n",
            "Batch 66.. Test loss: 1.174.. Accuracy: 0.625.. \n",
            "Batch 67.. Test loss: 1.051.. Accuracy: 0.6875.. \n",
            "Batch 68.. Test loss: 1.050.. Accuracy: 0.703125.. \n",
            "Batch 69.. Test loss: 1.116.. Accuracy: 0.625.. \n",
            "Batch 70.. Test loss: 1.010.. Accuracy: 0.671875.. \n",
            "Batch 71.. Test loss: 1.081.. Accuracy: 0.671875.. \n",
            "Batch 72.. Test loss: 1.166.. Accuracy: 0.65625.. \n",
            "Batch 73.. Test loss: 1.286.. Accuracy: 0.578125.. \n",
            "Batch 74.. Test loss: 1.171.. Accuracy: 0.640625.. \n",
            "Batch 75.. Test loss: 1.330.. Accuracy: 0.5625.. \n",
            "Batch 76.. Test loss: 1.165.. Accuracy: 0.59375.. \n",
            "Batch 77.. Test loss: 1.182.. Accuracy: 0.6875.. \n",
            "Batch 78.. Test loss: 1.313.. Accuracy: 0.515625.. \n",
            "Batch 79.. Test loss: 1.291.. Accuracy: 0.59375.. \n",
            "Batch 80.. Test loss: 1.225.. Accuracy: 0.59375.. \n",
            "Batch 81.. Test loss: 1.140.. Accuracy: 0.671875.. \n",
            "Batch 82.. Test loss: 1.402.. Accuracy: 0.5.. \n",
            "Batch 83.. Test loss: 1.183.. Accuracy: 0.625.. \n",
            "Batch 84.. Test loss: 1.196.. Accuracy: 0.546875.. \n",
            "Batch 85.. Test loss: 1.107.. Accuracy: 0.59375.. \n",
            "Batch 86.. Test loss: 1.321.. Accuracy: 0.46875.. \n",
            "Batch 87.. Test loss: 1.201.. Accuracy: 0.625.. \n",
            "Batch 88.. Test loss: 1.296.. Accuracy: 0.65625.. \n",
            "Batch 89.. Test loss: 1.442.. Accuracy: 0.578125.. \n",
            "Batch 90.. Test loss: 1.167.. Accuracy: 0.5625.. \n",
            "Batch 91.. Test loss: 1.248.. Accuracy: 0.546875.. \n",
            "Batch 92.. Test loss: 1.405.. Accuracy: 0.53125.. \n",
            "Batch 93.. Test loss: 1.231.. Accuracy: 0.609375.. \n",
            "Batch 94.. Test loss: 1.235.. Accuracy: 0.609375.. \n",
            "Batch 95.. Test loss: 1.337.. Accuracy: 0.515625.. \n",
            "Batch 96.. Test loss: 1.297.. Accuracy: 0.515625.. \n",
            "Batch 97.. Test loss: 1.476.. Accuracy: 0.484375.. \n",
            "Batch 98.. Test loss: 1.351.. Accuracy: 0.5625.. \n",
            "Batch 99.. Test loss: 1.116.. Accuracy: 0.703125.. \n",
            "Batch 100.. Test loss: 1.392.. Accuracy: 0.484375.. \n",
            "Batch 101.. Test loss: 1.156.. Accuracy: 0.625.. \n",
            "Batch 102.. Test loss: 1.273.. Accuracy: 0.578125.. \n",
            "Batch 103.. Test loss: 1.190.. Accuracy: 0.59375.. \n",
            "Batch 104.. Test loss: 1.258.. Accuracy: 0.546875.. \n",
            "Batch 105.. Test loss: 1.320.. Accuracy: 0.625.. \n",
            "Batch 106.. Test loss: 1.180.. Accuracy: 0.625.. \n",
            "Batch 107.. Test loss: 1.033.. Accuracy: 0.734375.. \n",
            "Batch 108.. Test loss: 1.239.. Accuracy: 0.578125.. \n",
            "Batch 109.. Test loss: 1.399.. Accuracy: 0.53125.. \n",
            "Batch 110.. Test loss: 1.243.. Accuracy: 0.5625.. \n",
            "Batch 111.. Test loss: 1.058.. Accuracy: 0.65625.. \n",
            "Batch 112.. Test loss: 1.080.. Accuracy: 0.6875.. \n",
            "Batch 113.. Test loss: 1.196.. Accuracy: 0.640625.. \n",
            "Batch 114.. Test loss: 1.259.. Accuracy: 0.59375.. \n",
            "Batch 115.. Test loss: 1.137.. Accuracy: 0.6875.. \n",
            "Batch 116.. Test loss: 1.281.. Accuracy: 0.515625.. \n",
            "Batch 117.. Test loss: 1.097.. Accuracy: 0.6875.. \n",
            "Batch 118.. Test loss: 1.137.. Accuracy: 0.6875.. \n",
            "Batch 119.. Test loss: 1.211.. Accuracy: 0.609375.. \n",
            "Batch 120.. Test loss: 1.160.. Accuracy: 0.625.. \n",
            "Batch 121.. Test loss: 1.160.. Accuracy: 0.546875.. \n",
            "Batch 122.. Test loss: 1.170.. Accuracy: 0.53125.. \n",
            "Batch 123.. Test loss: 1.307.. Accuracy: 0.59375.. \n",
            "Batch 124.. Test loss: 1.112.. Accuracy: 0.59375.. \n",
            "Batch 125.. Test loss: 1.121.. Accuracy: 0.640625.. \n",
            "Batch 126.. Test loss: 1.149.. Accuracy: 0.640625.. \n",
            "Batch 127.. Test loss: 1.350.. Accuracy: 0.4375.. \n",
            "Batch 128.. Test loss: 0.991.. Accuracy: 0.71875.. \n",
            "Batch 129.. Test loss: 1.257.. Accuracy: 0.578125.. \n",
            "Batch 130.. Test loss: 1.268.. Accuracy: 0.5625.. \n",
            "Batch 131.. Test loss: 1.300.. Accuracy: 0.59375.. \n",
            "Batch 132.. Test loss: 1.215.. Accuracy: 0.546875.. \n",
            "Batch 133.. Test loss: 1.280.. Accuracy: 0.6875.. \n",
            "Batch 134.. Test loss: 1.087.. Accuracy: 0.6875.. \n",
            "Batch 135.. Test loss: 1.227.. Accuracy: 0.59375.. \n",
            "Batch 136.. Test loss: 1.233.. Accuracy: 0.59375.. \n",
            "Batch 137.. Test loss: 1.293.. Accuracy: 0.578125.. \n",
            "Batch 138.. Test loss: 1.059.. Accuracy: 0.59375.. \n",
            "Batch 139.. Test loss: 1.216.. Accuracy: 0.609375.. \n",
            "Batch 140.. Test loss: 1.050.. Accuracy: 0.6875.. \n",
            "Batch 141.. Test loss: 1.134.. Accuracy: 0.59375.. \n",
            "Batch 142.. Test loss: 1.346.. Accuracy: 0.5.. \n",
            "Batch 143.. Test loss: 1.160.. Accuracy: 0.609375.. \n",
            "Batch 144.. Test loss: 1.034.. Accuracy: 0.609375.. \n",
            "Batch 145.. Test loss: 1.239.. Accuracy: 0.546875.. \n",
            "Batch 146.. Test loss: 1.258.. Accuracy: 0.53125.. \n",
            "Batch 147.. Test loss: 1.095.. Accuracy: 0.640625.. \n",
            "Batch 148.. Test loss: 1.225.. Accuracy: 0.578125.. \n",
            "Batch 149.. Test loss: 1.015.. Accuracy: 0.671875.. \n",
            "Batch 150.. Test loss: 1.118.. Accuracy: 0.65625.. \n",
            "Batch 151.. Test loss: 1.282.. Accuracy: 0.59375.. \n",
            "Batch 152.. Test loss: 1.074.. Accuracy: 0.609375.. \n",
            "Batch 153.. Test loss: 1.443.. Accuracy: 0.4375.. \n",
            "Batch 154.. Test loss: 1.184.. Accuracy: 0.5625.. \n",
            "Batch 155.. Test loss: 1.192.. Accuracy: 0.59375.. \n",
            "Batch 156.. Test loss: 1.308.. Accuracy: 0.5.. \n"
          ]
        }
      ],
      "source": [
        "batch = 0\n",
        "\n",
        "preds = []\n",
        "true = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    model.eval()\n",
        "    for images, labels in testloader:\n",
        "      \n",
        "      images = images.to(\"cuda\")\n",
        "      labels = labels.to(\"cuda\")\n",
        "      \n",
        "      batch += 1\n",
        "      \n",
        "      logps = model.forward(images)\n",
        "      test_loss = criterion(logps, labels)\n",
        "\n",
        "      ps = torch.exp(logps)\n",
        "      top_p, top_class = ps.topk(1, dim=1)\n",
        "      equals = top_class == labels.view(*top_class.shape)\n",
        "      accuracy = torch.mean(equals.type(torch.FloatTensor)).item()\n",
        "      \n",
        "      true.append([labels.view(*top_class.shape).view(64)])\n",
        "      preds.append([top_class.view(64)])\n",
        "    \n",
        "\n",
        "      print(f\"Batch {batch}.. \"\n",
        "            f\"Test loss: {test_loss:.3f}.. \"\n",
        "            f\"Accuracy: {accuracy}.. \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zoMsfcIm0qL2"
      },
      "source": [
        "**First note that accuracy is roughly 55% across all batches.  This is not bad considering the minimal amount of work needed to get this running.  Even better when considering the minimal amount of optimization performed to get the best configuration and hyperparamters.  Keep in mind, a random guess would give 10% accuracy.  5x improvement over random is not bad for one weekend of work.**\n",
        "\n",
        "**This is the power of transfer learning.  If somone else has already done the heavy lifting, there is no need to go through all that yourself.  It is time consuming and expensive to architect very deep neural networks.  If someone has already incurred that expense, nobody else has to start from scratch again.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "918JB_QbM3xH"
      },
      "source": [
        "**With all that being said, overall accuracy does not tell the whole story.  Is the model better on some classes than others?  When the model misses, is there systematic bias?  This will be interesting to evaluate.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JFvPUbcfNzvd"
      },
      "source": [
        "**First the output will be converted from lists to one dimensional tensors.  Those tensors will then be converted to arrays so that a convenient built-in function can be used.  Here the data is renamed at each step to allow tracking of the different data objects created.  It is fine to overwrite the old data structures with the new ones if the user is confident.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "3egElHh04fza"
      },
      "outputs": [],
      "source": [
        "# initialize empty tensors and make tensor conversions\n",
        "\n",
        "true_tensor = torch.empty(len(true), 64)\n",
        "preds_tensor = torch.empty(len(true), 64)\n",
        "\n",
        "for i in range(len(true)):\n",
        "  true_tensor[i] = torch.stack(true[i])\n",
        "  preds_tensor[i] = torch.stack(preds[i])\n",
        "\n",
        "# convert the tensor to 1-d\n",
        "true_1d = true_tensor.view(true_tensor.shape[0]*true_tensor.shape[1])\n",
        "preds_1d = preds_tensor.view(preds_tensor.shape[0]*preds_tensor.shape[1])\n",
        "\n",
        "# convert the 1-d tensors to 1-d numpy arrays\n",
        "true_class = true_1d.numpy()\n",
        "predicted_class = preds_1d.numpy()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7uXSPcKOTvcg"
      },
      "source": [
        "**Now a confusion matrix will be constructed.  A function is defined that can convert the raw counts to either precision or recall or simply keep the raw counts as a default.  Filling the matrix with either precision or recall sometimes gives better context than raw counts.  Typically when raw counts are displayed, most people start scrambling to convert to those percentages anyway.  However, viewing the raw counts is very useful as well.**\n",
        "\n",
        "**It should be mentioned, the author has used the terms precision and recall loosely here as those would only technically be the diagonals of the outputted matrices.  These terms are used for brevity and hopefully the reader takes away the idea behind displaying and evaluating these values.**\n",
        "\n",
        "**That being said, the confustion matrix will serve two purposes.  First, instead of showing overall accuracy, this will give an idea of which classes the model is better at classifying.  This could lead to many adjustments both within the model itself or in how the model is used.  Second, it shows what is happening when the model \"misses\".  No model is perfect but some are useful.  Knowing the limitations and biases inherent in a model will make it far more useful.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZvQi4S3Haqn"
      },
      "source": [
        "**The function is defined below.  Explanation is given within the comments of the function.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "6aVeESC4K6ru"
      },
      "outputs": [],
      "source": [
        "def cm_metrics(matrix_of_confusion, classes, metric = 'raw'):\n",
        "    \"\"\"\n",
        "    This function returns a confusion matrix with recall or precision \n",
        "    instead of raw counts.  Recall is the number of correct predictions \n",
        "    divided by the number of true examples for a given class.  Precision\n",
        "    is the number of correct predictions divided by the number predicted\n",
        "    for a given class.  This function assumes that true labels are \n",
        "    represented by the x-axis and predictions are represented by the y-axis.\n",
        "    \n",
        "    inputs:\n",
        "        matrix_ of_confusion: a numpy array (output of \n",
        "        sklearn.metrics.confusion_matrix()) and outputs a \n",
        "\n",
        "        classes: a list of class labels in the order they appear in \n",
        "        the confusion matrix (order of indexes)\n",
        "        \n",
        "        metric: either 'precision' or 'recall'\n",
        "              \n",
        "    returns: a pandas dataframe with the requested matrix\n",
        "    \"\"\"\n",
        "    \n",
        "    # ensure pandas is imported\n",
        "    \n",
        "    import pandas as pd\n",
        "    \n",
        "    # compute the correct matrix given the desired output\n",
        "    \n",
        "    if metric == 'recall':\n",
        "        row_sums = matrix_of_confusion.sum(axis = 1)\n",
        "        return_matrix = matrix_of_confusion/row_sums[:, None] \n",
        "    \n",
        "    elif metric == 'precision':\n",
        "        col_sums = matrix_of_confusion.sum(axis = 0)\n",
        "        return_matrix = matrix_of_confusion/col_sums[None, :] \n",
        "        \n",
        "    elif metric == 'raw':\n",
        "        return_matrix = matrix_of_confusion\n",
        "    \n",
        "    #convert output to dataframe with classes displayed\n",
        "    \n",
        "    cmdf = pd.DataFrame(return_matrix)\n",
        "    cmdf.columns = classes\n",
        "    \n",
        "    cl = pd.DataFrame(classes)\n",
        "    cl.columns = ['Classes']\n",
        "    \n",
        "    return_df = pd.concat([cl, cmdf], axis = 1)\n",
        "    \n",
        "    return return_df\n",
        "        "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJfBv1LiK-BA"
      },
      "source": [
        "**The tuple of classes needs to be converted to a list and the builtin confusion matrix function run and stored.  Then the function is run on recall and precision in that order.  A perfect model would have all 1s on the diagonal.  The rest of the entries will require careful observation to understand how the model misses.**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "NwA3Coy6EWNS"
      },
      "outputs": [],
      "source": [
        "# convert the classes tuple to a list\n",
        "cl = list(classes)\n",
        "\n",
        "# run built in function and store confusion matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(true_class, predicted_class)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "fcjnloAoPxDk",
        "outputId": "f59bb183-6af6-411b-8e86-f7c08c1d51a8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Classes  airplane  automobile  bird  cat  deer  dog  frog  horse  ship  \\\n",
              "0    airplane       591          33    37    5    10    2    12      3   270   \n",
              "1  automobile        10         826     4   11     1    0    13      4    61   \n",
              "2        bird       131          26   413   72    54   27   192     14    44   \n",
              "3         cat        24          35    53  326    11  142   247     25    39   \n",
              "4        deer        20           6    68   34   389   13   341     80    32   \n",
              "5         dog        14          21    46  159    11  507    95     55    37   \n",
              "6        frog         6          12    36   29     5    2   887      3     8   \n",
              "7       horse        32          16    27   40    96   52    72    529    37   \n",
              "8        ship        41          42    10    5     2    3    16      2   841   \n",
              "9       truck        22         223     2   12     3    4    14      2    85   \n",
              "\n",
              "   truck  \n",
              "0     35  \n",
              "1     69  \n",
              "2     26  \n",
              "3     95  \n",
              "4     17  \n",
              "5     52  \n",
              "6     12  \n",
              "7     96  \n",
              "8     35  \n",
              "9    633  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-11f9bb0c-c137-4017-8518-d15263faa1d1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Classes</th>\n",
              "      <th>airplane</th>\n",
              "      <th>automobile</th>\n",
              "      <th>bird</th>\n",
              "      <th>cat</th>\n",
              "      <th>deer</th>\n",
              "      <th>dog</th>\n",
              "      <th>frog</th>\n",
              "      <th>horse</th>\n",
              "      <th>ship</th>\n",
              "      <th>truck</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>airplane</td>\n",
              "      <td>591</td>\n",
              "      <td>33</td>\n",
              "      <td>37</td>\n",
              "      <td>5</td>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>12</td>\n",
              "      <td>3</td>\n",
              "      <td>270</td>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>automobile</td>\n",
              "      <td>10</td>\n",
              "      <td>826</td>\n",
              "      <td>4</td>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>4</td>\n",
              "      <td>61</td>\n",
              "      <td>69</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>bird</td>\n",
              "      <td>131</td>\n",
              "      <td>26</td>\n",
              "      <td>413</td>\n",
              "      <td>72</td>\n",
              "      <td>54</td>\n",
              "      <td>27</td>\n",
              "      <td>192</td>\n",
              "      <td>14</td>\n",
              "      <td>44</td>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>cat</td>\n",
              "      <td>24</td>\n",
              "      <td>35</td>\n",
              "      <td>53</td>\n",
              "      <td>326</td>\n",
              "      <td>11</td>\n",
              "      <td>142</td>\n",
              "      <td>247</td>\n",
              "      <td>25</td>\n",
              "      <td>39</td>\n",
              "      <td>95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>deer</td>\n",
              "      <td>20</td>\n",
              "      <td>6</td>\n",
              "      <td>68</td>\n",
              "      <td>34</td>\n",
              "      <td>389</td>\n",
              "      <td>13</td>\n",
              "      <td>341</td>\n",
              "      <td>80</td>\n",
              "      <td>32</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>dog</td>\n",
              "      <td>14</td>\n",
              "      <td>21</td>\n",
              "      <td>46</td>\n",
              "      <td>159</td>\n",
              "      <td>11</td>\n",
              "      <td>507</td>\n",
              "      <td>95</td>\n",
              "      <td>55</td>\n",
              "      <td>37</td>\n",
              "      <td>52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>frog</td>\n",
              "      <td>6</td>\n",
              "      <td>12</td>\n",
              "      <td>36</td>\n",
              "      <td>29</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>887</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>horse</td>\n",
              "      <td>32</td>\n",
              "      <td>16</td>\n",
              "      <td>27</td>\n",
              "      <td>40</td>\n",
              "      <td>96</td>\n",
              "      <td>52</td>\n",
              "      <td>72</td>\n",
              "      <td>529</td>\n",
              "      <td>37</td>\n",
              "      <td>96</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>ship</td>\n",
              "      <td>41</td>\n",
              "      <td>42</td>\n",
              "      <td>10</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>16</td>\n",
              "      <td>2</td>\n",
              "      <td>841</td>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>truck</td>\n",
              "      <td>22</td>\n",
              "      <td>223</td>\n",
              "      <td>2</td>\n",
              "      <td>12</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>14</td>\n",
              "      <td>2</td>\n",
              "      <td>85</td>\n",
              "      <td>633</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-11f9bb0c-c137-4017-8518-d15263faa1d1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-11f9bb0c-c137-4017-8518-d15263faa1d1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-11f9bb0c-c137-4017-8518-d15263faa1d1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ],
      "source": [
        "cm_metrics(cm, cl)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "pwrNaSimIErL",
        "outputId": "4d590735-4c3e-4bb5-f009-03bf3c573829"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Classes  airplane  automobile      bird       cat      deer       dog  \\\n",
              "0    airplane  0.592184    0.033066  0.037074  0.005010  0.010020  0.002004   \n",
              "1  automobile  0.010010    0.826827  0.004004  0.011011  0.001001  0.000000   \n",
              "2        bird  0.131131    0.026026  0.413413  0.072072  0.054054  0.027027   \n",
              "3         cat  0.024072    0.035105  0.053159  0.326981  0.011033  0.142427   \n",
              "4        deer  0.020000    0.006000  0.068000  0.034000  0.389000  0.013000   \n",
              "5         dog  0.014042    0.021063  0.046138  0.159478  0.011033  0.508526   \n",
              "6        frog  0.006000    0.012000  0.036000  0.029000  0.005000  0.002000   \n",
              "7       horse  0.032096    0.016048  0.027081  0.040120  0.096289  0.052156   \n",
              "8        ship  0.041123    0.042126  0.010030  0.005015  0.002006  0.003009   \n",
              "9       truck  0.022000    0.223000  0.002000  0.012000  0.003000  0.004000   \n",
              "\n",
              "       frog     horse      ship     truck  \n",
              "0  0.012024  0.003006  0.270541  0.035070  \n",
              "1  0.013013  0.004004  0.061061  0.069069  \n",
              "2  0.192192  0.014014  0.044044  0.026026  \n",
              "3  0.247743  0.025075  0.039117  0.095286  \n",
              "4  0.341000  0.080000  0.032000  0.017000  \n",
              "5  0.095286  0.055165  0.037111  0.052156  \n",
              "6  0.887000  0.003000  0.008000  0.012000  \n",
              "7  0.072217  0.530592  0.037111  0.096289  \n",
              "8  0.016048  0.002006  0.843531  0.035105  \n",
              "9  0.014000  0.002000  0.085000  0.633000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8443f466-277a-4cc8-9fe7-a436a548945e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Classes</th>\n",
              "      <th>airplane</th>\n",
              "      <th>automobile</th>\n",
              "      <th>bird</th>\n",
              "      <th>cat</th>\n",
              "      <th>deer</th>\n",
              "      <th>dog</th>\n",
              "      <th>frog</th>\n",
              "      <th>horse</th>\n",
              "      <th>ship</th>\n",
              "      <th>truck</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>airplane</td>\n",
              "      <td>0.592184</td>\n",
              "      <td>0.033066</td>\n",
              "      <td>0.037074</td>\n",
              "      <td>0.005010</td>\n",
              "      <td>0.010020</td>\n",
              "      <td>0.002004</td>\n",
              "      <td>0.012024</td>\n",
              "      <td>0.003006</td>\n",
              "      <td>0.270541</td>\n",
              "      <td>0.035070</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>automobile</td>\n",
              "      <td>0.010010</td>\n",
              "      <td>0.826827</td>\n",
              "      <td>0.004004</td>\n",
              "      <td>0.011011</td>\n",
              "      <td>0.001001</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.013013</td>\n",
              "      <td>0.004004</td>\n",
              "      <td>0.061061</td>\n",
              "      <td>0.069069</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>bird</td>\n",
              "      <td>0.131131</td>\n",
              "      <td>0.026026</td>\n",
              "      <td>0.413413</td>\n",
              "      <td>0.072072</td>\n",
              "      <td>0.054054</td>\n",
              "      <td>0.027027</td>\n",
              "      <td>0.192192</td>\n",
              "      <td>0.014014</td>\n",
              "      <td>0.044044</td>\n",
              "      <td>0.026026</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>cat</td>\n",
              "      <td>0.024072</td>\n",
              "      <td>0.035105</td>\n",
              "      <td>0.053159</td>\n",
              "      <td>0.326981</td>\n",
              "      <td>0.011033</td>\n",
              "      <td>0.142427</td>\n",
              "      <td>0.247743</td>\n",
              "      <td>0.025075</td>\n",
              "      <td>0.039117</td>\n",
              "      <td>0.095286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>deer</td>\n",
              "      <td>0.020000</td>\n",
              "      <td>0.006000</td>\n",
              "      <td>0.068000</td>\n",
              "      <td>0.034000</td>\n",
              "      <td>0.389000</td>\n",
              "      <td>0.013000</td>\n",
              "      <td>0.341000</td>\n",
              "      <td>0.080000</td>\n",
              "      <td>0.032000</td>\n",
              "      <td>0.017000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>dog</td>\n",
              "      <td>0.014042</td>\n",
              "      <td>0.021063</td>\n",
              "      <td>0.046138</td>\n",
              "      <td>0.159478</td>\n",
              "      <td>0.011033</td>\n",
              "      <td>0.508526</td>\n",
              "      <td>0.095286</td>\n",
              "      <td>0.055165</td>\n",
              "      <td>0.037111</td>\n",
              "      <td>0.052156</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>frog</td>\n",
              "      <td>0.006000</td>\n",
              "      <td>0.012000</td>\n",
              "      <td>0.036000</td>\n",
              "      <td>0.029000</td>\n",
              "      <td>0.005000</td>\n",
              "      <td>0.002000</td>\n",
              "      <td>0.887000</td>\n",
              "      <td>0.003000</td>\n",
              "      <td>0.008000</td>\n",
              "      <td>0.012000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>horse</td>\n",
              "      <td>0.032096</td>\n",
              "      <td>0.016048</td>\n",
              "      <td>0.027081</td>\n",
              "      <td>0.040120</td>\n",
              "      <td>0.096289</td>\n",
              "      <td>0.052156</td>\n",
              "      <td>0.072217</td>\n",
              "      <td>0.530592</td>\n",
              "      <td>0.037111</td>\n",
              "      <td>0.096289</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>ship</td>\n",
              "      <td>0.041123</td>\n",
              "      <td>0.042126</td>\n",
              "      <td>0.010030</td>\n",
              "      <td>0.005015</td>\n",
              "      <td>0.002006</td>\n",
              "      <td>0.003009</td>\n",
              "      <td>0.016048</td>\n",
              "      <td>0.002006</td>\n",
              "      <td>0.843531</td>\n",
              "      <td>0.035105</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>truck</td>\n",
              "      <td>0.022000</td>\n",
              "      <td>0.223000</td>\n",
              "      <td>0.002000</td>\n",
              "      <td>0.012000</td>\n",
              "      <td>0.003000</td>\n",
              "      <td>0.004000</td>\n",
              "      <td>0.014000</td>\n",
              "      <td>0.002000</td>\n",
              "      <td>0.085000</td>\n",
              "      <td>0.633000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8443f466-277a-4cc8-9fe7-a436a548945e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8443f466-277a-4cc8-9fe7-a436a548945e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8443f466-277a-4cc8-9fe7-a436a548945e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ],
      "source": [
        "cm_metrics(cm, cl, metric = 'recall')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "h1-Vs-V7IGNx",
        "outputId": "23fff6f8-292d-4ad9-fda0-5b19c02e047a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Classes  airplane  automobile      bird       cat      deer       dog  \\\n",
              "0    airplane  0.663300    0.026613  0.053161  0.007215  0.017182  0.002660   \n",
              "1  automobile  0.011223    0.666129  0.005747  0.015873  0.001718  0.000000   \n",
              "2        bird  0.147026    0.020968  0.593391  0.103896  0.092784  0.035904   \n",
              "3         cat  0.026936    0.028226  0.076149  0.470418  0.018900  0.188830   \n",
              "4        deer  0.022447    0.004839  0.097701  0.049062  0.668385  0.017287   \n",
              "5         dog  0.015713    0.016935  0.066092  0.229437  0.018900  0.674202   \n",
              "6        frog  0.006734    0.009677  0.051724  0.041847  0.008591  0.002660   \n",
              "7       horse  0.035915    0.012903  0.038793  0.057720  0.164948  0.069149   \n",
              "8        ship  0.046016    0.033871  0.014368  0.007215  0.003436  0.003989   \n",
              "9       truck  0.024691    0.179839  0.002874  0.017316  0.005155  0.005319   \n",
              "\n",
              "       frog     horse      ship     truck  \n",
              "0  0.006353  0.004184  0.185695  0.032710  \n",
              "1  0.006882  0.005579  0.041953  0.064486  \n",
              "2  0.101641  0.019526  0.030261  0.024299  \n",
              "3  0.130757  0.034868  0.026823  0.088785  \n",
              "4  0.180519  0.111576  0.022008  0.015888  \n",
              "5  0.050291  0.076709  0.025447  0.048598  \n",
              "6  0.469561  0.004184  0.005502  0.011215  \n",
              "7  0.038115  0.737796  0.025447  0.089720  \n",
              "8  0.008470  0.002789  0.578404  0.032710  \n",
              "9  0.007411  0.002789  0.058459  0.591589  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b33eeb7a-1e0f-4577-9d9a-61ff75055a86\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Classes</th>\n",
              "      <th>airplane</th>\n",
              "      <th>automobile</th>\n",
              "      <th>bird</th>\n",
              "      <th>cat</th>\n",
              "      <th>deer</th>\n",
              "      <th>dog</th>\n",
              "      <th>frog</th>\n",
              "      <th>horse</th>\n",
              "      <th>ship</th>\n",
              "      <th>truck</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>airplane</td>\n",
              "      <td>0.663300</td>\n",
              "      <td>0.026613</td>\n",
              "      <td>0.053161</td>\n",
              "      <td>0.007215</td>\n",
              "      <td>0.017182</td>\n",
              "      <td>0.002660</td>\n",
              "      <td>0.006353</td>\n",
              "      <td>0.004184</td>\n",
              "      <td>0.185695</td>\n",
              "      <td>0.032710</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>automobile</td>\n",
              "      <td>0.011223</td>\n",
              "      <td>0.666129</td>\n",
              "      <td>0.005747</td>\n",
              "      <td>0.015873</td>\n",
              "      <td>0.001718</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.006882</td>\n",
              "      <td>0.005579</td>\n",
              "      <td>0.041953</td>\n",
              "      <td>0.064486</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>bird</td>\n",
              "      <td>0.147026</td>\n",
              "      <td>0.020968</td>\n",
              "      <td>0.593391</td>\n",
              "      <td>0.103896</td>\n",
              "      <td>0.092784</td>\n",
              "      <td>0.035904</td>\n",
              "      <td>0.101641</td>\n",
              "      <td>0.019526</td>\n",
              "      <td>0.030261</td>\n",
              "      <td>0.024299</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>cat</td>\n",
              "      <td>0.026936</td>\n",
              "      <td>0.028226</td>\n",
              "      <td>0.076149</td>\n",
              "      <td>0.470418</td>\n",
              "      <td>0.018900</td>\n",
              "      <td>0.188830</td>\n",
              "      <td>0.130757</td>\n",
              "      <td>0.034868</td>\n",
              "      <td>0.026823</td>\n",
              "      <td>0.088785</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>deer</td>\n",
              "      <td>0.022447</td>\n",
              "      <td>0.004839</td>\n",
              "      <td>0.097701</td>\n",
              "      <td>0.049062</td>\n",
              "      <td>0.668385</td>\n",
              "      <td>0.017287</td>\n",
              "      <td>0.180519</td>\n",
              "      <td>0.111576</td>\n",
              "      <td>0.022008</td>\n",
              "      <td>0.015888</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>dog</td>\n",
              "      <td>0.015713</td>\n",
              "      <td>0.016935</td>\n",
              "      <td>0.066092</td>\n",
              "      <td>0.229437</td>\n",
              "      <td>0.018900</td>\n",
              "      <td>0.674202</td>\n",
              "      <td>0.050291</td>\n",
              "      <td>0.076709</td>\n",
              "      <td>0.025447</td>\n",
              "      <td>0.048598</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>frog</td>\n",
              "      <td>0.006734</td>\n",
              "      <td>0.009677</td>\n",
              "      <td>0.051724</td>\n",
              "      <td>0.041847</td>\n",
              "      <td>0.008591</td>\n",
              "      <td>0.002660</td>\n",
              "      <td>0.469561</td>\n",
              "      <td>0.004184</td>\n",
              "      <td>0.005502</td>\n",
              "      <td>0.011215</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>horse</td>\n",
              "      <td>0.035915</td>\n",
              "      <td>0.012903</td>\n",
              "      <td>0.038793</td>\n",
              "      <td>0.057720</td>\n",
              "      <td>0.164948</td>\n",
              "      <td>0.069149</td>\n",
              "      <td>0.038115</td>\n",
              "      <td>0.737796</td>\n",
              "      <td>0.025447</td>\n",
              "      <td>0.089720</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>ship</td>\n",
              "      <td>0.046016</td>\n",
              "      <td>0.033871</td>\n",
              "      <td>0.014368</td>\n",
              "      <td>0.007215</td>\n",
              "      <td>0.003436</td>\n",
              "      <td>0.003989</td>\n",
              "      <td>0.008470</td>\n",
              "      <td>0.002789</td>\n",
              "      <td>0.578404</td>\n",
              "      <td>0.032710</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>truck</td>\n",
              "      <td>0.024691</td>\n",
              "      <td>0.179839</td>\n",
              "      <td>0.002874</td>\n",
              "      <td>0.017316</td>\n",
              "      <td>0.005155</td>\n",
              "      <td>0.005319</td>\n",
              "      <td>0.007411</td>\n",
              "      <td>0.002789</td>\n",
              "      <td>0.058459</td>\n",
              "      <td>0.591589</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b33eeb7a-1e0f-4577-9d9a-61ff75055a86')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b33eeb7a-1e0f-4577-9d9a-61ff75055a86 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b33eeb7a-1e0f-4577-9d9a-61ff75055a86');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ],
      "source": [
        "cm_metrics(cm, cl, metric = 'precision')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CyU7-cWgeNZf"
      },
      "source": [
        "**Knowing the strengths and weaknesses of a model is very important for two main reasons:**\n",
        "\n",
        "**The first reason is that the model can then be used effectively in its current state.  Assigning a degree of confidence to different types of predictions can help to guide decisions made using the model's output.  It may cause someone to ignore certain types of predictions and/or take swift action based on others.  Ignorantly regarding every type of output as the same is a big mistake often made by relatively smart people.  Take the time to learn nuances of any model.**\n",
        "\n",
        "**The other reason it is important is because knowledge of the current state can help accelerate development and get the model to a better state.  This could mean changing the inputs, architecture, hyperparameters, etc. of the model and retraining.  In this case, simply training longer would probably yield benefits.  It can also mean treating the probabilities differently.  In the above example automobile is predicted often when the model should be predicting truck.  Perhaps try shifting some of the automobile predictions with high truck probability to a truck assignment and assess accuracy.  There is no law stating that the highest probability gets the prediction.  It is usually the best method.  But there are exceptions.**\n",
        "\n",
        "**What other trends in misclassification are present?  Are there any other possible solutions?**"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qomDddIH3ZD0"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "transfer_learning_image.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}