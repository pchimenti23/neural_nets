{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o_iRmBWK1Zrt"
   },
   "source": [
    "**This notebook walks through the steps of applying transfer learning for image recognition.  Pytorch has many pretrained models that can be adapted to a given application.  The pretrained models simply need to be loaded and adapated for the given application.**\n",
    "\n",
    "**For this case, ten objects will be classified from the CIFAR-10 (https://www.cs.toronto.edu/~kriz/cifar.html) data set.  The pretrained Inception-v3 (https://arxiv.org/abs/1512.00567) model will be adapted to classify these images.**\n",
    "\n",
    "**The ten objects to be classified are:**\n",
    "\n",
    "*   airplane\n",
    "*   automobile\n",
    "*   bird\n",
    "*   cat\n",
    "*   deer\n",
    "*   dog\n",
    "*   frog\n",
    "*   horse\n",
    "*   ship\n",
    "*   truck\n",
    "\n",
    "**Note that truck here refers to large semi type trucks.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8UhAEpQt_u0Z"
   },
   "source": [
    "**First load the necessary packages.  Note that 'models' is being imported from 'torchvision'.  This gives access to many pretrained models.  Pretrained models can be obtained elsewhere as well but this package gives plenty of options for our purposes.**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8rKyNz1U__mc"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms, models\n",
    "\n",
    "#from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A2jJRRDVSQO9"
   },
   "source": [
    "**The CIFAR-10 data set is included in the `torchvision.datasets` module.  It is loaded below.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U-9Ihm4IXTpF"
   },
   "source": [
    "**Images need to undergo transformations before being loaded.  First the transforms for the training set are defined.**\n",
    "\n",
    "**The random rotation aids in training.  It will allow the network to see the image from different angles during each training pass.  This will help the network to generalize.  Randomness is also added to the cropping step.  The inception v3 net is unique in that it expects size 299 (299x299 pixels).  Most models take size 224 but sometimes it is fun to be different.  A random horizontal flip is added to further aid in generalization and the normalization is defined to fit what the pretrained network expects.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jB_ByaEfXbdG"
   },
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([transforms.RandomRotation(30),\n",
    "                                       transforms.RandomResizedCrop(299),\n",
    "                                       transforms.RandomHorizontalFlip(),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                            [0.229, 0.224, 0.225])])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E19SwHjhZMp3"
   },
   "source": [
    "**No randomness is added to the test set as accuracy should be graded on the true images.  However, they are resized and then cropped to fit what the net expects.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7ASpCPEuXcD0"
   },
   "outputs": [],
   "source": [
    "test_transforms = transforms.Compose([transforms.Resize(320),\n",
    "                                      transforms.CenterCrop(299),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                           [0.229, 0.224, 0.225])])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lIN0ACfgafqW"
   },
   "source": [
    "**The train and test set are loaded below using the data loader utility.  Batches of 64 images at a time will be passed through the model.  The training set will be randomly shuffled to prevent the net from picking up patterns based on the order images are seen.  This is not necessary for the test set.  Notice that the train and test transforms are applied at this step.**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "GTgT2EI4SQbM",
    "outputId": "c6eb5fbc-43c4-479f-d311-01ca52c93ee1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=train_transforms)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=test_transforms)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SK7QwfGEapMz"
   },
   "source": [
    "**The classes are defined listed below in the order they are indexed (alphabetically).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xJDbwoc4apgV"
   },
   "outputs": [],
   "source": [
    "classes = ('airplane', 'automobile', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JmkT3JB3rv4m"
   },
   "source": [
    "**The inception v3 model is loaded and described below.  It is pretrained but the output configuration needs to be determined in order to properly attach new layers.  Only 10 output layers are needed for this classification problem whereas the pretrained model outputs 1,000.  The key here is to recognize that the last layer takes 2,048 features and is named as (fc).  A small neural net will basically be attached to this layer and a new output layer will be constructed.  Syntactically this new small net will be named as (fc) and will replace the old output layer.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 7055
    },
    "colab_type": "code",
    "id": "EJQvHo6Okj9x",
    "outputId": "33e2e15e-265c-4f76-9471-a6db0f2e90be"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/inception_v3_google-1a9a5a14.pth\" to /root/.torch/models/inception_v3_google-1a9a5a14.pth\n",
      "108857766it [00:01, 90671655.86it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Inception3(\n",
       "  (Conv2d_1a_3x3): BasicConv2d(\n",
       "    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Conv2d_2a_3x3): BasicConv2d(\n",
       "    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Conv2d_2b_3x3): BasicConv2d(\n",
       "    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Conv2d_3b_1x1): BasicConv2d(\n",
       "    (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Conv2d_4a_3x3): BasicConv2d(\n",
       "    (conv): Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Mixed_5b): InceptionA(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_1): BasicConv2d(\n",
       "      (conv): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_2): BasicConv2d(\n",
       "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_5c): InceptionA(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_1): BasicConv2d(\n",
       "      (conv): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_2): BasicConv2d(\n",
       "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_5d): InceptionA(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_1): BasicConv2d(\n",
       "      (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_2): BasicConv2d(\n",
       "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_6a): InceptionB(\n",
       "    (branch3x3): BasicConv2d(\n",
       "      (conv): Conv2d(288, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_6b): InceptionC(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_2): BasicConv2d(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_3): BasicConv2d(\n",
       "      (conv): Conv2d(128, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_4): BasicConv2d(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_5): BasicConv2d(\n",
       "      (conv): Conv2d(128, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_6c): InceptionC(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_2): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_3): BasicConv2d(\n",
       "      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_4): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_5): BasicConv2d(\n",
       "      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_6d): InceptionC(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_2): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_3): BasicConv2d(\n",
       "      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_4): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_5): BasicConv2d(\n",
       "      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_6e): InceptionC(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_2): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_3): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_4): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_5): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (AuxLogits): InceptionAux(\n",
       "    (conv0): BasicConv2d(\n",
       "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv1): BasicConv2d(\n",
       "      (conv): Conv2d(128, 768, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (fc): Linear(in_features=768, out_features=1000, bias=True)\n",
       "  )\n",
       "  (Mixed_7a): InceptionD(\n",
       "    (branch3x3_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_2): BasicConv2d(\n",
       "      (conv): Conv2d(192, 320, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7x3_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7x3_2): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7x3_3): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7x3_4): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_7b): InceptionE(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_1): BasicConv2d(\n",
       "      (conv): Conv2d(1280, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_2a): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_2b): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(1280, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3a): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3b): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(1280, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_7c): InceptionE(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(2048, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_1): BasicConv2d(\n",
       "      (conv): Conv2d(2048, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_2a): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_2b): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(2048, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3a): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3b): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(2048, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.inception_v3(pretrained = True)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jpHOcv8o-AuD"
   },
   "source": [
    "**The first step in constructing a custom net from a pretrained net is to freeze the pretrained model.  New layers will be trained but the everything about the pretrained model being leveraged should remain the same.  Therefore the gradients are turned off.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_nTy9zEJnSVc"
   },
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gg1FQgPY-ok1"
   },
   "source": [
    "**Now the old output layer will be replaced with the small net defined below.  It will start with a layer that takes 2,048 features as its input and it will output a log probability for each class.**\n",
    "\n",
    "**Two fully connected rectified linear (ReLU) layers are built.  The first takes in the 2,048 features the model currently inputs to its output layer and instead outputs 500 features.  The next layer inputs those 500 and outputs 250 features.  Finally, those 250 features are converted into 10 outputs with a log softmax layer.  Note that dropout of .2 is used for both ReLU layers to combat overfitting.  This image classifier is trained to recognize 1,000 different image classes and this application only needs to classify 10**\n",
    "\n",
    "**A good exercise would be to play with this architecture and see how it affects final accuracy.  Only a few tests were done on different configurations due to a limited gpu budget and time constraints.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PH6TCvNLnsCa"
   },
   "outputs": [],
   "source": [
    "model.fc = nn.Sequential(nn.Linear(2048, 500),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Dropout(.2), \n",
    "                                 nn.Linear(500, 250),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Dropout(.2), \n",
    "                                 nn.Linear(250, 10),\n",
    "                                 nn.LogSoftmax(dim=1))          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0VPLFd2hAxXA"
   },
   "source": [
    "**Negative log likelihood loss is chosen as the cost function.  Adam is chosen as the optimizer.  Documentation on the Adam optimizer is easy to find but outside the scope of this tutorial.  At this point, it is sufficient to know that it is basically a \"souped up\" version of gradient descent.**\n",
    "\n",
    "**Note the `to(\"cuda\")` command when defining the loss function.  This is the first of a few objects that needs to be moved to the gpu to drastically speed up training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iLCJyl-yAUMj"
   },
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss().to(\"cuda\")\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BVTHqe4QBjy9"
   },
   "source": [
    "**Now the model is ready to be trained.  Loss is being tracked after every batch just for fun.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u1DPsRdjxdiO"
   },
   "source": [
    "**Much of the code below is explained in the 'income_model_binary_nn.ipynb' notebook in the same repo as this notebook.  This code is tracked differently simply for demonstration purposes and because it is fun to watch the model work (at least for me).**\n",
    "\n",
    "**A big difference worth addressing is following two lines:**\n",
    "\n",
    "                  `logps_t = model.forward(images)\n",
    "                   logps = logps_t[0] #inception v3 outputs a tuple in train mode`\n",
    "                    \n",
    "**The code above is necessary because the inception v3 model outputs a tuple containing two tensors.  Position `[0]` in the tensor is the log proabilities that are needed to make predictions.  Position `[1]` contains the auxiliary logits with dimesionality equal to the original model's output (1,000).  That output is not needed so the log probabilities are stored and the auxiliary logits are ignored.**\n",
    "\n",
    "**A fun exercise would be to store the batch and loss and make some plots that (hopefully) show the loss decreasing.  This is usually tracked across epochs but that takes a lot longer to run and gpu time can be limited for most people.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Br-ET5x0k3Uw"
   },
   "outputs": [],
   "source": [
    "model = model.to(\"cuda\") #model is also moved to the gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XbEVdBhfCTx7"
   },
   "outputs": [],
   "source": [
    "epochs = 2\n",
    "batch = 0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "     \n",
    "    running_loss = 0\n",
    "    \n",
    "    for images, labels in trainloader:\n",
    "      \n",
    "        #images and labels are moved to gpu as well\n",
    "        images = images.to(\"cuda\")\n",
    "        labels = labels.to(\"cuda\")\n",
    "        \n",
    "        batch += 1\n",
    "        \n",
    "        model.train()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        logps_t = model.forward(images)\n",
    "        logps = logps_t[0] #inception v3 outputs a tuple in train mode\n",
    "        loss = criterion(logps, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "#         print(f\"Epoch {epoch+1} Batch {batch}.. \"\n",
    "#               f\"Train loss: {train_loss:.3f}.. \")\n",
    "\n",
    "    train_loss = running_loss/batch\n",
    "\n",
    "    print(f\"Epoch {epoch+1}.. \"\n",
    "          f\"Train loss: {train_loss:.3f}.. \")\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8MLpXygs0wsu"
   },
   "source": [
    "**Since this model has only been run for one epoch, the full model can be saved and training resumed at a later time.  Code to load the model is provided below as well.**\n",
    "\n",
    "**First the google drive will be mounted and then the model will be saved in a folder called 'models' in the google drive.  The mounting code only needs to be run once per session so comment it out after running if models will be saved/loaded multiple times.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_sEA6oOA0pM8"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FN6Mjc812guZ"
   },
   "source": [
    "**The model has been named 'inception_v3_transfer' and stored on the drive.  It can be loaded with the code that is currently commented out.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x0cAIiyX2jYJ"
   },
   "outputs": [],
   "source": [
    "# model_name = 'inception_v3_transfer.pt'\n",
    "# path = F'/content/gdrive/My Drive/models/{model_name}'\n",
    "# torch.save(model, path)\n",
    "\n",
    "# model = torch.load('/content/gdrive/My Drive/models/inception_v3_transfer.pt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CUEvT0p8wsrp"
   },
   "source": [
    "**Predictions are made below.  Loss and accuracy are both tracked but should not change by batch outside of some random variation.  The model has been switched to evaluation mode so that it will remain static.  In regular practice, accuracy for each batch would be stored and aggregated to get an overall accuracy metric.**\n",
    "\n",
    "**Note that in evaluation mode, this model now only outputs the tensor of log probabilities.  This is because the auxiliary logits are only needed for training.  And since log probabilities are less useful, the `torch.exp()` function is used to convert the output to probabilities.**\n",
    "\n",
    "**The predictions and labels are also being stored to do some fun analysis.  `preds` and `true` will store the predictions and true labels, respectively, as a list of tensors.  Data manipulations will be performed to make it possible to get some specific information about model performance.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UOiW15fUP5J4"
   },
   "outputs": [],
   "source": [
    "batch = 0\n",
    "\n",
    "preds = []\n",
    "true = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    for images, labels in testloader:\n",
    "      \n",
    "      images = images.to(\"cuda\")\n",
    "      labels = labels.to(\"cuda\")\n",
    "      \n",
    "      batch += 1\n",
    "      \n",
    "      logps = model.forward(images)\n",
    "      test_loss = criterion(logps, labels)\n",
    "\n",
    "      ps = torch.exp(logps)\n",
    "      top_p, top_class = ps.topk(1, dim=1)\n",
    "      equals = top_class == labels.view(*top_class.shape)\n",
    "      accuracy = torch.mean(equals.type(torch.FloatTensor)).item()\n",
    "      \n",
    "      true.append([labels.view(*top_class.shape).view(64)])\n",
    "      preds.append([top_class.view(64)])\n",
    "    \n",
    "\n",
    "      print(f\"Batch {batch}.. \"\n",
    "            f\"Test loss: {test_loss:.3f}.. \"\n",
    "            f\"Accuracy: {accuracy}.. \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zoMsfcIm0qL2"
   },
   "source": [
    "**First note that accuracy is roughly 55% across all batches.  This is not bad considering the minimal amount of work needed to get this running.  Even better when considering the minimal amount of optimization performed to get the best configuration and hyperparamters.  Keep in mind, a random guess would give 10% accuracy.  5x improvement over random is not bad for one weekend of work.**\n",
    "\n",
    "**This is the power of transfer learning.  If somone else has already done the heavy lifting, there is no need to go through all that yourself.  It is time consuming and expensive to architect very deep neural networks.  If someone has already incurred that expense, nobody else has to start from scratch again.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "918JB_QbM3xH"
   },
   "source": [
    "**With all that being said, overall accuracy does not tell the whole story.  Is the model better on some classes than others?  When the model misses, is there systematic bias?  This will be interesting to evaluate.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JFvPUbcfNzvd"
   },
   "source": [
    "**First the output will be converted from lists to one dimensional tensors.  Those tensors will then be converted to arrays so that a convenient built-in function can be used.  Here the data is renamed at each step to allow tracking of the different data objects created.  It is fine to overwrite the old data structures with the new ones if the user is confident.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3egElHh04fza"
   },
   "outputs": [],
   "source": [
    "# initialize empty tensors and make tensor conversions\n",
    "\n",
    "true_tensor = torch.empty(len(true), 64)\n",
    "preds_tensor = torch.empty(len(true), 64)\n",
    "\n",
    "for i in range(len(true)):\n",
    "  true_tensor[i] = torch.stack(true[i])\n",
    "  preds_tensor[i] = torch.stack(preds[i])\n",
    "\n",
    "# convert the tensor to 1-d\n",
    "true_1d = true_tensor.view(true_tensor.shape[0]*true_tensor.shape[1])\n",
    "preds_1d = preds_tensor.view(preds_tensor.shape[0]*preds_tensor.shape[1])\n",
    "\n",
    "# convert the 1-d tensors to 1-d numpy arrays\n",
    "true_class = true_1d.numpy()\n",
    "predicted_class = preds_1d.numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7uXSPcKOTvcg"
   },
   "source": [
    "**Now a confusion matrix will be constructed.  A function is defined that can convert the raw counts to either precision or recall or simply keep the raw counts as a default.  Filling the matrix with either precision or recall sometimes gives better context than raw counts.  Typically when raw counts are displayed, most people start scrambling to convert to those percentages anyway.  However, viewing the raw counts is very useful as well.**\n",
    "\n",
    "**It should be mentioned, the author has used the terms precision and recall loosely here as those would only technically be the diagonals of the outputted matrices.  These terms are used for brevity and hopefully the reader takes away the idea behind displaying and evaluating these values.**\n",
    "\n",
    "**That being said, the confustion matrix will serve two purposes.  First, instead of showing overall accuracy, this will give an idea of which classes the model is better at classifying.  This could lead to many adjustments both within the model itself or in how the model is used.  Second, it shows what is happening when the model \"misses\".  No model is perfect but some are useful.  Knowing the limitations and biases inherent in a model will make it far more useful.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QZvQi4S3Haqn"
   },
   "source": [
    "**The function is defined below.  Explanation is given within the comments of the function.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6aVeESC4K6ru"
   },
   "outputs": [],
   "source": [
    "def cm_metrics(matrix_of_confusion, classes, metric = 'raw'):\n",
    "    \"\"\"\n",
    "    This function takes returns a confusion matrix with recall or precision \n",
    "    instead of raw counts.  Recall is the number of correct predictions \n",
    "    divided by the number of true examples for a given class.  Precision\n",
    "    is the number of correct prections divided by the number predicted\n",
    "    for a given class.  This function assumes that true labels are \n",
    "    represented by the x-axis and predictions are represented by the y-axis.\n",
    "    \n",
    "    inputs:\n",
    "        matrix_ of_confusion: a numpy array (output of \n",
    "        sklearn.metrics.confusion_matrix()) and outputs a \n",
    "\n",
    "        classes: a list of class labels in the order they appear in \n",
    "        the confusion matrix (order of indexes)\n",
    "        \n",
    "        metric: either 'precision' or 'recall'\n",
    "              \n",
    "    returns: a pandas dataframe with the requested matrix\n",
    "    \"\"\"\n",
    "    \n",
    "    # ensure pandas is imported\n",
    "    \n",
    "    import pandas as pd\n",
    "    \n",
    "    # compute the correct matrix given the desired output\n",
    "    \n",
    "    if metric == 'recall':\n",
    "        row_sums = matrix_of_confusion.sum(axis = 1)\n",
    "        return_matrix = matrix_of_confusion/row_sums[:, None] \n",
    "    \n",
    "    elif metric == 'precision':\n",
    "        col_sums = matrix_of_confusion.sum(axis = 0)\n",
    "        return_matrix = matrix_of_confusion/col_sums[None, :] \n",
    "        \n",
    "    elif metric == 'raw':\n",
    "        return_matrix = matrix_of_confusion\n",
    "    \n",
    "    #convert output to dataframe with classes displayed\n",
    "    \n",
    "    cmdf = pd.DataFrame(return_matrix)\n",
    "    cmdf.columns = classes\n",
    "    \n",
    "    cl = pd.DataFrame(classes)\n",
    "    cl.columns = ['Classes']\n",
    "    \n",
    "    return_df = pd.concat([cl, cmdf], axis = 1)\n",
    "    \n",
    "    return return_df\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MJfBv1LiK-BA"
   },
   "source": [
    "**The tuple of classes needs to be converted to a list and the builtin confusion matrix function run and stored.  Then the function is run on recall and precision in that order.  A perfect model would have all 1s on the diagonal.  The rest of the entries will require careful observation to understand how the model misses.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NwA3Coy6EWNS"
   },
   "outputs": [],
   "source": [
    "# convert the classes tuple to a list\n",
    "cl = list(classes)\n",
    "\n",
    "# run built in function and store confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(true_class, predicted_class)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "colab_type": "code",
    "id": "fcjnloAoPxDk",
    "outputId": "fff79b35-3538-4519-db04-19e1a111d8d4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classes</th>\n",
       "      <th>airplane</th>\n",
       "      <th>automobile</th>\n",
       "      <th>bird</th>\n",
       "      <th>cat</th>\n",
       "      <th>deer</th>\n",
       "      <th>dog</th>\n",
       "      <th>frog</th>\n",
       "      <th>horse</th>\n",
       "      <th>ship</th>\n",
       "      <th>truck</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>airplane</td>\n",
       "      <td>654</td>\n",
       "      <td>31</td>\n",
       "      <td>29</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>33</td>\n",
       "      <td>232</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>automobile</td>\n",
       "      <td>28</td>\n",
       "      <td>847</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>21</td>\n",
       "      <td>64</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bird</td>\n",
       "      <td>179</td>\n",
       "      <td>18</td>\n",
       "      <td>352</td>\n",
       "      <td>32</td>\n",
       "      <td>111</td>\n",
       "      <td>18</td>\n",
       "      <td>122</td>\n",
       "      <td>123</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cat</td>\n",
       "      <td>59</td>\n",
       "      <td>43</td>\n",
       "      <td>64</td>\n",
       "      <td>247</td>\n",
       "      <td>28</td>\n",
       "      <td>103</td>\n",
       "      <td>204</td>\n",
       "      <td>177</td>\n",
       "      <td>45</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>deer</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>55</td>\n",
       "      <td>10</td>\n",
       "      <td>451</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>236</td>\n",
       "      <td>29</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>dog</td>\n",
       "      <td>34</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "      <td>85</td>\n",
       "      <td>32</td>\n",
       "      <td>398</td>\n",
       "      <td>59</td>\n",
       "      <td>261</td>\n",
       "      <td>40</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>frog</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>51</td>\n",
       "      <td>27</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>841</td>\n",
       "      <td>25</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>horse</td>\n",
       "      <td>49</td>\n",
       "      <td>9</td>\n",
       "      <td>22</td>\n",
       "      <td>9</td>\n",
       "      <td>56</td>\n",
       "      <td>16</td>\n",
       "      <td>21</td>\n",
       "      <td>777</td>\n",
       "      <td>21</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ship</td>\n",
       "      <td>74</td>\n",
       "      <td>33</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>839</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>truck</td>\n",
       "      <td>45</td>\n",
       "      <td>490</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>64</td>\n",
       "      <td>103</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Classes  airplane  automobile  bird  cat  deer  dog  frog  horse  ship  \\\n",
       "0    airplane       654          31    29    3    10    1     4     33   232   \n",
       "1  automobile        28         847     2    5     1    0    14     21    64   \n",
       "2        bird       179          18   352   32   111   18   122    123    39   \n",
       "3         cat        59          43    64  247    28  103   204    177    45   \n",
       "4        deer        29           4    55   10   451    1   178    236    29   \n",
       "5         dog        34          24    48   85    32  398    59    261    40   \n",
       "6        frog        12           6    51   27    21    1   841     25    12   \n",
       "7       horse        49           9    22    9    56   16    21    777    21   \n",
       "8        ship        74          33     5    4     9    3    10     12   839   \n",
       "9       truck        45         490     2    6     2    2    10     64   103   \n",
       "\n",
       "   truck  \n",
       "0      1  \n",
       "1     17  \n",
       "2      5  \n",
       "3     27  \n",
       "4      7  \n",
       "5     16  \n",
       "6      4  \n",
       "7     17  \n",
       "8      8  \n",
       "9    276  "
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm_metrics(cm, cl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "colab_type": "code",
    "id": "pwrNaSimIErL",
    "outputId": "580e0660-164c-4bc0-ea2e-e96e53ff02fb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classes</th>\n",
       "      <th>airplane</th>\n",
       "      <th>automobile</th>\n",
       "      <th>bird</th>\n",
       "      <th>cat</th>\n",
       "      <th>deer</th>\n",
       "      <th>dog</th>\n",
       "      <th>frog</th>\n",
       "      <th>horse</th>\n",
       "      <th>ship</th>\n",
       "      <th>truck</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>airplane</td>\n",
       "      <td>0.655311</td>\n",
       "      <td>0.031062</td>\n",
       "      <td>0.029058</td>\n",
       "      <td>0.003006</td>\n",
       "      <td>0.010020</td>\n",
       "      <td>0.001002</td>\n",
       "      <td>0.004008</td>\n",
       "      <td>0.033066</td>\n",
       "      <td>0.232465</td>\n",
       "      <td>0.001002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>automobile</td>\n",
       "      <td>0.028028</td>\n",
       "      <td>0.847848</td>\n",
       "      <td>0.002002</td>\n",
       "      <td>0.005005</td>\n",
       "      <td>0.001001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014014</td>\n",
       "      <td>0.021021</td>\n",
       "      <td>0.064064</td>\n",
       "      <td>0.017017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bird</td>\n",
       "      <td>0.179179</td>\n",
       "      <td>0.018018</td>\n",
       "      <td>0.352352</td>\n",
       "      <td>0.032032</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.018018</td>\n",
       "      <td>0.122122</td>\n",
       "      <td>0.123123</td>\n",
       "      <td>0.039039</td>\n",
       "      <td>0.005005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cat</td>\n",
       "      <td>0.059178</td>\n",
       "      <td>0.043129</td>\n",
       "      <td>0.064193</td>\n",
       "      <td>0.247743</td>\n",
       "      <td>0.028084</td>\n",
       "      <td>0.103310</td>\n",
       "      <td>0.204614</td>\n",
       "      <td>0.177533</td>\n",
       "      <td>0.045135</td>\n",
       "      <td>0.027081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>deer</td>\n",
       "      <td>0.029000</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>0.055000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.451000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.178000</td>\n",
       "      <td>0.236000</td>\n",
       "      <td>0.029000</td>\n",
       "      <td>0.007000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>dog</td>\n",
       "      <td>0.034102</td>\n",
       "      <td>0.024072</td>\n",
       "      <td>0.048144</td>\n",
       "      <td>0.085256</td>\n",
       "      <td>0.032096</td>\n",
       "      <td>0.399198</td>\n",
       "      <td>0.059178</td>\n",
       "      <td>0.261785</td>\n",
       "      <td>0.040120</td>\n",
       "      <td>0.016048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>frog</td>\n",
       "      <td>0.012000</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>0.051000</td>\n",
       "      <td>0.027000</td>\n",
       "      <td>0.021000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.841000</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.012000</td>\n",
       "      <td>0.004000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>horse</td>\n",
       "      <td>0.049147</td>\n",
       "      <td>0.009027</td>\n",
       "      <td>0.022066</td>\n",
       "      <td>0.009027</td>\n",
       "      <td>0.056169</td>\n",
       "      <td>0.016048</td>\n",
       "      <td>0.021063</td>\n",
       "      <td>0.779338</td>\n",
       "      <td>0.021063</td>\n",
       "      <td>0.017051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ship</td>\n",
       "      <td>0.074223</td>\n",
       "      <td>0.033099</td>\n",
       "      <td>0.005015</td>\n",
       "      <td>0.004012</td>\n",
       "      <td>0.009027</td>\n",
       "      <td>0.003009</td>\n",
       "      <td>0.010030</td>\n",
       "      <td>0.012036</td>\n",
       "      <td>0.841525</td>\n",
       "      <td>0.008024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>truck</td>\n",
       "      <td>0.045000</td>\n",
       "      <td>0.490000</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.064000</td>\n",
       "      <td>0.103000</td>\n",
       "      <td>0.276000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Classes  airplane  automobile      bird       cat      deer       dog  \\\n",
       "0    airplane  0.655311    0.031062  0.029058  0.003006  0.010020  0.001002   \n",
       "1  automobile  0.028028    0.847848  0.002002  0.005005  0.001001  0.000000   \n",
       "2        bird  0.179179    0.018018  0.352352  0.032032  0.111111  0.018018   \n",
       "3         cat  0.059178    0.043129  0.064193  0.247743  0.028084  0.103310   \n",
       "4        deer  0.029000    0.004000  0.055000  0.010000  0.451000  0.001000   \n",
       "5         dog  0.034102    0.024072  0.048144  0.085256  0.032096  0.399198   \n",
       "6        frog  0.012000    0.006000  0.051000  0.027000  0.021000  0.001000   \n",
       "7       horse  0.049147    0.009027  0.022066  0.009027  0.056169  0.016048   \n",
       "8        ship  0.074223    0.033099  0.005015  0.004012  0.009027  0.003009   \n",
       "9       truck  0.045000    0.490000  0.002000  0.006000  0.002000  0.002000   \n",
       "\n",
       "       frog     horse      ship     truck  \n",
       "0  0.004008  0.033066  0.232465  0.001002  \n",
       "1  0.014014  0.021021  0.064064  0.017017  \n",
       "2  0.122122  0.123123  0.039039  0.005005  \n",
       "3  0.204614  0.177533  0.045135  0.027081  \n",
       "4  0.178000  0.236000  0.029000  0.007000  \n",
       "5  0.059178  0.261785  0.040120  0.016048  \n",
       "6  0.841000  0.025000  0.012000  0.004000  \n",
       "7  0.021063  0.779338  0.021063  0.017051  \n",
       "8  0.010030  0.012036  0.841525  0.008024  \n",
       "9  0.010000  0.064000  0.103000  0.276000  "
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm_metrics(cm, cl, metric = 'recall')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "colab_type": "code",
    "id": "h1-Vs-V7IGNx",
    "outputId": "cb3aaf8a-39a3-4783-8edb-75f9f175874d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classes</th>\n",
       "      <th>airplane</th>\n",
       "      <th>automobile</th>\n",
       "      <th>bird</th>\n",
       "      <th>cat</th>\n",
       "      <th>deer</th>\n",
       "      <th>dog</th>\n",
       "      <th>frog</th>\n",
       "      <th>horse</th>\n",
       "      <th>ship</th>\n",
       "      <th>truck</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>airplane</td>\n",
       "      <td>0.562339</td>\n",
       "      <td>0.020598</td>\n",
       "      <td>0.046032</td>\n",
       "      <td>0.007009</td>\n",
       "      <td>0.013870</td>\n",
       "      <td>0.001842</td>\n",
       "      <td>0.002734</td>\n",
       "      <td>0.019086</td>\n",
       "      <td>0.162921</td>\n",
       "      <td>0.002646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>automobile</td>\n",
       "      <td>0.024076</td>\n",
       "      <td>0.562791</td>\n",
       "      <td>0.003175</td>\n",
       "      <td>0.011682</td>\n",
       "      <td>0.001387</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009569</td>\n",
       "      <td>0.012146</td>\n",
       "      <td>0.044944</td>\n",
       "      <td>0.044974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bird</td>\n",
       "      <td>0.153912</td>\n",
       "      <td>0.011960</td>\n",
       "      <td>0.558730</td>\n",
       "      <td>0.074766</td>\n",
       "      <td>0.153953</td>\n",
       "      <td>0.033149</td>\n",
       "      <td>0.083390</td>\n",
       "      <td>0.071139</td>\n",
       "      <td>0.027388</td>\n",
       "      <td>0.013228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cat</td>\n",
       "      <td>0.050731</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.101587</td>\n",
       "      <td>0.577103</td>\n",
       "      <td>0.038835</td>\n",
       "      <td>0.189687</td>\n",
       "      <td>0.139440</td>\n",
       "      <td>0.102371</td>\n",
       "      <td>0.031601</td>\n",
       "      <td>0.071429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>deer</td>\n",
       "      <td>0.024936</td>\n",
       "      <td>0.002658</td>\n",
       "      <td>0.087302</td>\n",
       "      <td>0.023364</td>\n",
       "      <td>0.625520</td>\n",
       "      <td>0.001842</td>\n",
       "      <td>0.121668</td>\n",
       "      <td>0.136495</td>\n",
       "      <td>0.020365</td>\n",
       "      <td>0.018519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>dog</td>\n",
       "      <td>0.029235</td>\n",
       "      <td>0.015947</td>\n",
       "      <td>0.076190</td>\n",
       "      <td>0.198598</td>\n",
       "      <td>0.044383</td>\n",
       "      <td>0.732965</td>\n",
       "      <td>0.040328</td>\n",
       "      <td>0.150954</td>\n",
       "      <td>0.028090</td>\n",
       "      <td>0.042328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>frog</td>\n",
       "      <td>0.010318</td>\n",
       "      <td>0.003987</td>\n",
       "      <td>0.080952</td>\n",
       "      <td>0.063084</td>\n",
       "      <td>0.029126</td>\n",
       "      <td>0.001842</td>\n",
       "      <td>0.574846</td>\n",
       "      <td>0.014459</td>\n",
       "      <td>0.008427</td>\n",
       "      <td>0.010582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>horse</td>\n",
       "      <td>0.042132</td>\n",
       "      <td>0.005980</td>\n",
       "      <td>0.034921</td>\n",
       "      <td>0.021028</td>\n",
       "      <td>0.077670</td>\n",
       "      <td>0.029466</td>\n",
       "      <td>0.014354</td>\n",
       "      <td>0.449393</td>\n",
       "      <td>0.014747</td>\n",
       "      <td>0.044974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ship</td>\n",
       "      <td>0.063629</td>\n",
       "      <td>0.021927</td>\n",
       "      <td>0.007937</td>\n",
       "      <td>0.009346</td>\n",
       "      <td>0.012483</td>\n",
       "      <td>0.005525</td>\n",
       "      <td>0.006835</td>\n",
       "      <td>0.006940</td>\n",
       "      <td>0.589185</td>\n",
       "      <td>0.021164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>truck</td>\n",
       "      <td>0.038693</td>\n",
       "      <td>0.325581</td>\n",
       "      <td>0.003175</td>\n",
       "      <td>0.014019</td>\n",
       "      <td>0.002774</td>\n",
       "      <td>0.003683</td>\n",
       "      <td>0.006835</td>\n",
       "      <td>0.037016</td>\n",
       "      <td>0.072331</td>\n",
       "      <td>0.730159</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Classes  airplane  automobile      bird       cat      deer       dog  \\\n",
       "0    airplane  0.562339    0.020598  0.046032  0.007009  0.013870  0.001842   \n",
       "1  automobile  0.024076    0.562791  0.003175  0.011682  0.001387  0.000000   \n",
       "2        bird  0.153912    0.011960  0.558730  0.074766  0.153953  0.033149   \n",
       "3         cat  0.050731    0.028571  0.101587  0.577103  0.038835  0.189687   \n",
       "4        deer  0.024936    0.002658  0.087302  0.023364  0.625520  0.001842   \n",
       "5         dog  0.029235    0.015947  0.076190  0.198598  0.044383  0.732965   \n",
       "6        frog  0.010318    0.003987  0.080952  0.063084  0.029126  0.001842   \n",
       "7       horse  0.042132    0.005980  0.034921  0.021028  0.077670  0.029466   \n",
       "8        ship  0.063629    0.021927  0.007937  0.009346  0.012483  0.005525   \n",
       "9       truck  0.038693    0.325581  0.003175  0.014019  0.002774  0.003683   \n",
       "\n",
       "       frog     horse      ship     truck  \n",
       "0  0.002734  0.019086  0.162921  0.002646  \n",
       "1  0.009569  0.012146  0.044944  0.044974  \n",
       "2  0.083390  0.071139  0.027388  0.013228  \n",
       "3  0.139440  0.102371  0.031601  0.071429  \n",
       "4  0.121668  0.136495  0.020365  0.018519  \n",
       "5  0.040328  0.150954  0.028090  0.042328  \n",
       "6  0.574846  0.014459  0.008427  0.010582  \n",
       "7  0.014354  0.449393  0.014747  0.044974  \n",
       "8  0.006835  0.006940  0.589185  0.021164  \n",
       "9  0.006835  0.037016  0.072331  0.730159  "
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm_metrics(cm, cl, metric = 'precision')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dpZW9LFVS2ie"
   },
   "source": [
    "**The observations below are made from viewing the confusion matrix pasted below.  It was generated after running only 12 test batches through the model.  It is meant to demonstrate the means by which the results whould be interpreted.  If a users results differ, please apply the concepts and not this direct knowledge.  Time permitting, more results can be generated to see if these trends hold.**\n",
    "\n",
    "**UPDATE:   After 120 batches, the trends still hold.  The model thinks that frogs resemble cats moreso than dogs.  This is not surprising, as the model had no opportunity to improve across test batches.  But it is good to account for small sample variation before making blanket statements about trends.**\n",
    "\n",
    "![](http://i67.tinypic.com/2dbku1w.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Jn8tQOdUNTZu"
   },
   "source": [
    "**As one might expect, the model frequently confuses the truck for an automobile.  When it sees a truck, it is almost as likely to think it saw an automobile as a truck.  However, when it thinks it sees a truck, it is usually correct.  Somewhat conversely, if it sees an automobile, it is very likely to identify it correctly.  However, it also falsely predicts that many trucks are also automobiles.**\n",
    "\n",
    "**This makes sense if you look at how often the model predicts automobile versus truck.  It predicts automobile a lot more than the number present in the test set.  In short, it overpredicts automobile and underpredicts truck.**\n",
    "\n",
    "**As one might also expect, the model confuses ships with airplanes and dogs with cats.  Most would have probably expected this outcome.**\n",
    "\n",
    "**What is somewhat surprising is that if the model sees a cat but gets it wrong, it predicts frog over twice as much as dog.  It still predicts cat most often when it sees a cat.  That is the good news.  But the model thinks frogs look more like cats than dogs do.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CyU7-cWgeNZf"
   },
   "source": [
    "**Knowing the strengths and weaknesses of a model is very important for two main reasons:**\n",
    "\n",
    "**The first reason is that the model can then be used effectively in its current state.  Assigning a degree of confidence to different types of predictions can help to guide decisions made using the model's output.  It may cause someone to ignore certain types of predictions and/or take swift action based on others.  Ignorantly regarding every type of output as the same is a big mistake often made by relatively smart people.  Take the time to learn nuances of any model.**\n",
    "\n",
    "**The other reason it is important is because knowledge of the current state can help accelerate development and get the model to a better state.  This could mean changing the inputs, architecture, hyperparameters, etc. of the model and retraining.  In this case, simply training longer would probably yield benefits.  It can also mean treating the probabilities differently.  In the above example automobile is predicted often when the model should be predicting truck.  Perhaps try shifting some of the automobile predictions with high truck probability to a truck assignment and assess accuracy.  There is no law stating that the highest probability gets the prediction.  It is usually the best method.  But there are exceptions.**"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "transfer_learning_image.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
